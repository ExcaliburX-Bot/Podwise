import requests
import json
import os
import re
import xml.etree.ElementTree as ET
from datetime import datetime
from email.utils import parsedate_to_datetime

# é»˜è®¤æ¼”ç¤ºåˆ—è¡¨ (ä»…å½“ OPML å½»åº•å¤±è´¥æ—¶ä½¿ç”¨)
DEFAULT_RSS = [
    "https://pythonhunter.org/episodes/feed.xml"
]

def parse_rss_episode(rss_url):
    """è§£æ RSS å¹¶æå–æœ€æ–°ä¸€é›†"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (PodwiseBot)'}
        # è®¾ç½® 8ç§’è¶…æ—¶
        response = requests.get(rss_url, headers=headers, timeout=8)
        
        if response.status_code != 200:
            return None
            
        # å°è¯•å¤„ç† encoding é—®é¢˜
        response.encoding = response.apparent_encoding

        root = ET.fromstring(response.content)
        channel = root.find('channel')
        if channel is None: channel = root 

        title_tag = channel.find('title')
        podcast_title = title_tag.text if title_tag is not None else "æœªçŸ¥æ’­å®¢"
        
        item = channel.find('item')
        if item is None: return None
            
        ep_title = item.find('title').text or "æ— æ ‡é¢˜"
        enclosure = item.find('enclosure')
        
        if enclosure is None: return None
            
        audio_url = enclosure.get('url')
        pub_date_str = item.find('pubDate').text
        
        try:
            pub_date = parsedate_to_datetime(pub_date_str).isoformat()
        except:
            pub_date = datetime.now().isoformat()

        return {
            "eid": audio_url[-15:],
            "title": ep_title,
            "podcast": {"title": podcast_title},
            "enclosureUrl": audio_url,
            "pubDate": pub_date,
            "source_rss": rss_url
        }
    except Exception:
        return None

def extract_urls_from_opml(file_path):
    urls = []
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶: {file_path}")
    
    # --- æ–¹æ³• A: æ ‡å‡† XML è§£æ (ä¸¥æ ¼) ---
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ xmlUrl æˆ– url å±æ€§
        for elem in root.iter():
            url = elem.get('xmlUrl') or elem.get('url')
            if url: urls.append(url)
        print(f"ğŸ‰ æ ‡å‡†æ¨¡å¼è§£ææˆåŠŸï¼æ‰¾åˆ° {len(urls)} ä¸ªæº")
        
    except Exception as e:
        print(f"âš ï¸ æ ‡å‡†è§£æå¤±è´¥ ({e})ï¼Œåˆ‡æ¢åˆ°æš´åŠ›æå–æ¨¡å¼...")
        
        # --- æ–¹æ³• B: æ­£åˆ™è¡¨è¾¾å¼æš´åŠ›æå– (å®¹é”™ç‡æé«˜) ---
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                # æŸ¥æ‰¾æ‰€æœ‰ xmlUrl="..." æˆ– url="..." çš„æ¨¡å¼
                # è¿™é‡Œçš„æ­£åˆ™ä¼šå¿½ç•¥ XML ç»“æ„ï¼Œç›´æ¥æ‰¾é“¾æ¥
                found = re.findall(r'(?:xmlUrl|url)=["\']([^"\']+)["\']', content)
                urls.extend(found)
            print(f"ğŸ’ª æš´åŠ›æ¨¡å¼æˆåŠŸï¼å¼ºè¡Œæå–åˆ° {len(urls)} ä¸ªæº")
        except Exception as e2:
            print(f"âŒ æš´åŠ›æ¨¡å¼ä¹Ÿå¤±è´¥äº†: {e2}")

    # å»é‡å¹¶è¿‡æ»¤é http å¼€å¤´çš„åƒåœ¾æ•°æ®
    clean_urls = list(set([u for u in urls if u.startswith('http')]))
    return clean_urls

def fetch_podcasts():
    os.makedirs('data', exist_ok=True)
    opml_path = 'data/subscriptions.opml'
    
    rss_list = []
    if os.path.exists(opml_path):
        rss_list = extract_urls_from_opml(opml_path)
    
    if not rss_list:
        print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆè®¢é˜…ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨")
        rss_list = DEFAULT_RSS

    print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(rss_list)} ä¸ªæ’­å®¢ (åªå–æœ€æ–°å‰ 30 æ¡)...")
    
    episodes = []
    # ä¸ºäº†é˜²æ­¢è¶…æ—¶ï¼Œå¦‚æœè®¢é˜…å¤ªå¤šï¼Œè¿™é‡Œé™åˆ¶åªå¤„ç†å‰ 50 ä¸ªè®¢é˜…æº
    # å¦‚æœä½ æƒ³å¤„ç†æ›´å¤šï¼Œå¯ä»¥æŠŠ [:50] å»æ‰
    target_list = rss_list[:50] 
    
    for i, rss in enumerate(target_list):
        print(f"[{i+1}/{len(target_list)}] æ£€æŸ¥ä¸­...", end="\r")
        episode = parse_rss_episode(rss)
        if episode:
            episodes.append(episode)
            
    # æŒ‰æ—¶é—´å€’åº
    episodes.sort(key=lambda x: x['pubDate'], reverse=True)
    final_data = episodes[:30]

    with open('data/hot_episodes.json', 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
        
    print(f"\n\nğŸ’¾ å®Œæˆï¼å·²ä¿å­˜ {len(final_data)} æ¡æœ€æ–°å•é›†ã€‚")

if __name__ == "__main__":
    fetch_podcasts()

