import requests
import json
import os
import xml.etree.ElementTree as ET
from datetime import datetime
from email.utils import parsedate_to_datetime

# é»˜è®¤è®¢é˜… (å½“æ‰¾ä¸åˆ° OPML æ–‡ä»¶æ—¶ä½¿ç”¨)
DEFAULT_RSS = [
    "https://feed.xyzfm.space/a9uD3-3ksD1u",
    "https://pythonhunter.org/episodes/feed.xml"
]

def extract_urls_from_opml(file_path):
    """ä» OPML æ–‡ä»¶ä¸­æå– RSS é“¾æ¥"""
    urls = []
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        # æŸ¥æ‰¾æ‰€æœ‰å«æœ‰ xmlUrl å±æ€§çš„ outline æ ‡ç­¾ (æ”¯æŒåµŒå¥—æ–‡ä»¶å¤¹)
        for outline in root.findall('.//outline'):
            url = outline.get('xmlUrl')
            if url:
                urls.append(url)
        print(f"ğŸ“‚ æˆåŠŸä» OPML åŠ è½½äº† {len(urls)} ä¸ªè®¢é˜…æº")
    except Exception as e:
        print(f"âš ï¸ è¯»å– OPML å¤±è´¥: {e}")
    return urls

def parse_rss_episode(rss_url):
    """è§£æ RSS å¹¶æå–æœ€æ–°ä¸€é›†"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; PodwiseBot/1.0; +https://github.com/)'
        }
        # è®¾ç½® 10ç§’è¶…æ—¶ï¼Œé˜²æ­¢æŸä¸ªæºå¡æ­»æ•´ä¸ªæµç¨‹
        response = requests.get(rss_url, headers=headers, timeout=10)
        
        # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 200ï¼Œç›´æ¥è·³è¿‡
        if response.status_code != 200:
            return None
            
        root = ET.fromstring(response.content)
        channel = root.find('channel')
        
        # è·å–æ’­å®¢æ ‡é¢˜
        podcast_title_tag = channel.find('title')
        podcast_title = podcast_title_tag.text if podcast_title_tag is not None else "æœªçŸ¥æ’­å®¢"
        
        # è·å–æœ€æ–°çš„ä¸€é›† (ç¬¬ä¸€ä¸ª item)
        item = channel.find('item')
        if item is None:
            return None
            
        title_tag = item.find('title')
        title = title_tag.text if title_tag is not None else "æ— æ ‡é¢˜"
        
        # å°è¯•è·å–éŸ³é¢‘é“¾æ¥
        enclosure = item.find('enclosure')
        if enclosure is None:
            return None # æ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡
            
        audio_url = enclosure.get('url')
        
        # å°è¯•è·å–å‘å¸ƒæ—¶é—´
        pub_date_str = item.find('pubDate').text
        try:
            pub_date = parsedate_to_datetime(pub_date_str).isoformat()
        except:
            pub_date = datetime.now().isoformat()

        return {
            "eid": audio_url[-15:], # ç®€æ˜“ ID
            "title": title,
            "podcast": {
                "title": podcast_title
            },
            "enclosureUrl": audio_url,
            "duration": 0,
            "pubDate": pub_date,
            "source_rss": rss_url
        }

    except Exception as e:
        # æŸä¸ªæºè§£æå¤±è´¥ä¸å½±å“å…¶ä»–æºï¼Œä»…æ‰“å°é”™è¯¯
        # print(f"   âŒ è§£æè·³è¿‡: {rss_url} ({str(e)[:30]}...)") 
        return None

def fetch_podcasts():
    os.makedirs('data', exist_ok=True)
    opml_path = 'data/subscriptions.opml'
    
    # 1. ç¡®å®šè®¢é˜…æºåˆ—è¡¨
    rss_list = []
    if os.path.exists(opml_path):
        print(f"ğŸ“„ å‘ç°è®¢é˜…æ–‡ä»¶: {opml_path}")
        rss_list = extract_urls_from_opml(opml_path)
    
    # å¦‚æœæ²¡æ‰¾åˆ°æ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨
    if not rss_list:
        print("âš ï¸ æœªæ‰¾åˆ° OPML æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æ¼”ç¤ºåˆ—è¡¨")
        rss_list = DEFAULT_RSS

    # 2. å¼€å§‹æŠ“å–
    print(f"ğŸš€ å¼€å§‹æ£€æŸ¥ {len(rss_list)} ä¸ªæ’­å®¢çš„æ›´æ–°...")
    episodes = []
    
    # é™åˆ¶æœ€å¤§æŠ“å–æ•°é‡ï¼Œé˜²æ­¢è¶…æ—¶ (ä¾‹å¦‚åªå–å‰ 50 ä¸ª)
    # å¦‚æœä½ çš„è®¢é˜…éå¸¸å¤šï¼Œå¯ä»¥è€ƒè™‘åˆ†æ‰¹å¤„ç†
    for i, rss in enumerate(rss_list):
        episode = parse_rss_episode(rss)
        if episode:
            episodes.append(episode)
            print(f"   âœ… [{len(episodes)}] {episode['podcast']['title']}: {episode['title'][:20]}...")
            
    # æŒ‰å‘å¸ƒæ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
    episodes.sort(key=lambda x: x['pubDate'], reverse=True)
    
    # åªä¿ç•™æœ€æ–°çš„ 20 æ¡ï¼Œé¿å…æŠ¥å‘Šå¤ªé•¿
    final_data = episodes[:20]

    output_file = 'data/hot_episodes.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
        
    print(f"\nğŸ’¾ æŠ“å–å®Œæˆï¼å·²ä¿å­˜ {len(final_data)} æ¡æœ€æ–°å•é›†ã€‚")

if __name__ == "__main__":
    fetch_podcasts()
