import feedparser
import json
import os
from datetime import datetime, timedelta

# ---åœ¨æ­¤å¤„ä¿®æ”¹ä½ çš„è®¢é˜…æº---
RSS_FEEDS = [
    "https://feeds.xyz/123", # è¯·æ›¿æ¢æˆä½ çœŸå®çš„ RSS åœ°å€
    "https://feeds.xyz/456",
]
# -----------------------

def fetch_rss():
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½• (scripts/)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # è·å–é¡¹ç›®æ ¹ç›®å½• (scripts çš„ä¸Šä¸€çº§)
    root_dir = os.path.dirname(current_dir)
    # æ•°æ®å­˜å‚¨ç›®å½•
    data_dir = os.path.join(root_dir, 'data')
    
    # å¦‚æœ data ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)

    all_episodes = []
    # ç­›é€‰æœ€è¿‘ 24 å°æ—¶
    yesterday = datetime.now() - timedelta(days=1)

    print(f"å¼€å§‹æŠ“å– {len(RSS_FEEDS)} ä¸ªè®¢é˜…æº...")

    for feed_url in RSS_FEEDS:
        try:
            print(f"æ­£åœ¨è¿æ¥: {feed_url} ...")
            feed = feedparser.parse(feed_url)
            podcast_title = feed.feed.get('title', 'Unknown Podcast')
            print(f"âœ… æˆåŠŸè·å–: {podcast_title}")

            for entry in feed.entries:
                try:
                    # è§£æå‘å¸ƒæ—¶é—´
                    if hasattr(entry, 'published_parsed'):
                        pub_date_parsed = entry.published_parsed
                        pub_date = datetime(*pub_date_parsed[:6])
                    else:
                        continue
                except:
                    continue

                # å¦‚æœæ˜¯æœ€è¿‘ 24 å°æ—¶æ›´æ–°çš„
                if pub_date > yesterday:
                    # 1. ä¼˜å…ˆè·å–ç½‘é¡µé“¾æ¥ (link)
                    web_link = entry.get('link', '')
                    
                    # 2. å¦‚æœæ²¡æœ‰ç½‘é¡µé“¾æ¥ï¼Œå°è¯•æ‰¾ enclosure (éŸ³é¢‘é“¾æ¥)
                    if not web_link and hasattr(entry, 'enclosures') and len(entry.enclosures) > 0:
                        web_link = entry.enclosures[0].href

                    # 3. å­˜å…¥åˆ—è¡¨
                    all_episodes.append({
                        'title': entry.title,
                        'podcast': {'title': podcast_title},
                        'link': web_link, # è¿™é‡Œå­˜çš„æ˜¯ç½‘é¡µé“¾æ¥
                        'pubDate': str(pub_date)
                    })
        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥ {feed_url}: {e}")

    # ä¿å­˜ç»“æœåˆ° data/hot_episodes.json
    output_file = os.path.join(data_dir, 'hot_episodes.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_episodes, f, ensure_ascii=False, indent=2)

    print(f"ğŸ‰ æŠ“å–å®Œæˆï¼å…±æ‰¾åˆ° {len(all_episodes)} ä¸ªæ–°å•é›†ã€‚")

if __name__ == "__main__":
    fetch_rss()
