import feedparser
import json
import os
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta

# ==========================================
# 1. å·²æ›¿æ¢ä¸ºä½ æä¾›çš„ä¸“ç”¨ä¿åº•é“¾æ¥
MANUAL_FEEDS = [
    "https://feed.xyzfm.space/dk4yh3pkpjp3"
]
# ==========================================

def parse_opml(opml_path):
    urls = []
    try:
        tree = ET.parse(opml_path)
        root = tree.getroot()
        for outline in root.findall('.//outline'):
            url = outline.get('xmlUrl')
            if url:
                urls.append(url)
        print(f"ğŸ“‚ æˆåŠŸä» OPML åŠ è½½äº† {len(urls)} ä¸ªè®¢é˜…æº")
    except Exception as e:
        print(f"âš ï¸ è¯»å– OPML å¤±è´¥: {e}")
    return urls

def get_best_link(entry):
    # ä¼˜å…ˆæ‰¾åŸæ–‡é“¾æ¥
    if entry.get('link'): return entry.get('link')
    # å…¶æ¬¡æ‰¾ alternate é“¾æ¥
    if entry.get('links'):
        for l in entry.get('links', []):
            if l.get('type') == 'text/html' or l.get('rel') == 'alternate':
                if l.get('href'): return l.get('href')
    # å†æ¬¡å°è¯• id
    id_val = entry.get('id', '')
    if id_val.startswith('http'): return id_val
    # æœ€åå°è¯•éŸ³é¢‘æ–‡ä»¶é“¾æ¥
    if entry.get('enclosures'): return entry.get('enclosures')[0].get('href')
    return ''

def fetch_rss():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    root_dir = os.path.dirname(current_dir)
    data_dir = os.path.join(root_dir, 'data')
    
    opml_path = os.path.join(root_dir, 'subscriptions.opml')
    
    rss_feeds = []
    # ä¼˜å…ˆè¯»å– OPMLï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¿åº•åˆ—è¡¨
    if os.path.exists(opml_path):
        rss_feeds = parse_opml(opml_path)
        # å¦‚æœ OPML é‡Œæ˜¯ç©ºçš„ï¼Œä¹ŸåŠ ä¸Šä¿åº•ï¼Œé˜²æ­¢å®Œå…¨æ²¡æ•°æ®
        if not rss_feeds:
            rss_feeds = MANUAL_FEEDS
    else:
        print("â„¹ï¸ æœªæ‰¾åˆ° subscriptions.opmlï¼Œä½¿ç”¨æ‰‹åŠ¨ä¿åº•åˆ—è¡¨")
        rss_feeds = MANUAL_FEEDS

    if not os.path.exists(data_dir):
        os.makedirs(data_dir)

    all_episodes = []
    
    # ==========================================
    # 2. æŠ“å–è¿‡å» 7 å¤©çš„æ›´æ–°ï¼Œç¡®ä¿é‚®ä»¶é‡Œæœ‰å†…å®¹
    time_threshold = datetime.now() - timedelta(days=7)
    # ==========================================

    print(f"ğŸš€ å¼€å§‹å¤„ç† {len(rss_feeds)} ä¸ªè®¢é˜…æº (æŸ¥æ‰¾ {time_threshold.strftime('%Y-%m-%d')} ä¹‹åçš„æ›´æ–°)...")

    for feed_url in rss_feeds:
        try:
            # è®¾ç½®è¶…æ—¶ï¼Œé˜²æ­¢å¡æ­»
            feed = feedparser.parse(feed_url)
            podcast_title = feed.feed.get('title', 'æœªçŸ¥æ’­å®¢')
            
            if not feed.entries:
                continue

            for entry in feed.entries:
                try:
                    # è§£ææ—¶é—´
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        pub_date_parsed = entry.published_parsed
                        pub_date = datetime(*pub_date_parsed[:6])
                    else:
                        # å¦‚æœæ²¡æ—¶é—´ï¼Œé»˜è®¤è·³è¿‡ï¼Œæˆ–è€…ä½ å¯ä»¥é€‰æ‹©å½“ä½œä»Šå¤©
                        continue
                except:
                    continue

                # ç­›é€‰æ—¶é—´
                if pub_date > time_threshold:
                    final_link = get_best_link(entry)
                    print(f"   âœ… æŠ“å–åˆ°: {podcast_title} - {entry.title[:15]}...")

                    all_episodes.append({
                        'title': entry.title,
                        'podcast': {'title': podcast_title},
                        'link': final_link,
                        'pubDate': str(pub_date)
                    })
        except Exception as e:
            print(f"âŒ é”™è¯¯ {feed_url}: {e}")

    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨æœ€å‰é¢ï¼‰
    all_episodes.sort(key=lambda x: x['pubDate'], reverse=True)

    output_file = os.path.join(data_dir, 'hot_episodes.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_episodes, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±æŠ“å–åˆ° {len(all_episodes)} ä¸ªæ–°å•é›†ã€‚")

if __name__ == "__main__":
    fetch_rss()
