import json
import os
import urllib.parse
from datetime import datetime

def generate_import_list():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    root_dir = os.path.dirname(current_dir)
    input_file = os.path.join(root_dir, 'data', 'hot_episodes.json')
    output_file = os.path.join(root_dir, 'PODWISE_IMPORT.md')
    
    if not os.path.exists(input_file):
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("æš‚æ— æ›´æ–°æ•°æ®")
        return

    with open(input_file, 'r', encoding='utf-8') as f:
        episodes = json.load(f)

    date_str = datetime.now().strftime('%Y-%m-%d')
    
    lines = []
    lines.append(f"# ğŸ™ï¸ æ’­å®¢æ›´æ–°æ—¥æŠ¥ ({date_str})")
    lines.append(f"ä»Šæ—¥æ›´æ–°: {len(episodes)} é›†\n")
    
    lines.append("## ğŸ“– è¯¦ç»†åˆ—è¡¨")
    for ep in episodes:
        title = ep.get('title', 'æ— æ ‡é¢˜').replace('|', '-')
        pod = ep.get('podcast', {}).get('title', 'æœªçŸ¥æ’­å®¢')
        link = ep.get('link', '')
        
        # --- ğŸ›¡ï¸ ä¿åº•æœºåˆ¶ ---
        # å¦‚æœé“¾æ¥ä¸ºç©ºï¼Œç”Ÿæˆä¸€ä¸ª Google æœç´¢é“¾æ¥
        if not link:
            query = urllib.parse.quote(f"{pod} {title}")
            link = f"https://www.google.com/search?q={query}"
        # ------------------
        
        lines.append(f"**[{title}]({link})**")
        lines.append(f"> ğŸ“» {pod}")
        lines.append("")

    lines.append("\n## ğŸ“‹ æ‰¹é‡å¤åˆ¶ (ç”¨äº Podwise å¯¼å…¥)")
    lines.append("```text")
    for ep in episodes:
        link = ep.get('link', '')
        if link and link.startswith('http'):
            lines.append(link)
    lines.append("```")

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    print(f"âœ… å·²ç”Ÿæˆé‚®ä»¶å†…å®¹: {output_file}")

if __name__ == "__main__":
    generate_import_list()
