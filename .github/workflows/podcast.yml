name: æ’­å®¢çƒ­æ¦œè‡ªåŠ¨æŠ“å–

on:
  workflow_dispatch:  # å…è®¸æ‰‹åŠ¨è§¦å‘
  schedule:
    - cron: '0 */6 * * *'  # æ¯6å°æ—¶è¿è¡Œä¸€æ¬¡

jobs:
  fetch-and-process:
    runs-on: ubuntu-latest
    
    steps:
      # æ­¥éª¤1ï¼šæ£€å‡ºä»£ç 
      - name: æ£€å‡ºä»“åº“
        uses: actions/checkout@v3
      
      # æ­¥éª¤2ï¼šè®¾ç½® Python ç¯å¢ƒ
      - name: è®¾ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      # æ­¥éª¤3ï¼šå®‰è£…ä¾èµ–
      - name: å®‰è£…ä¾èµ–
        run: |
          pip install requests
      
      # æ­¥éª¤4ï¼šæŠ“å–æ‰€æœ‰æ’­å®¢æ•°æ®
      - name: æŠ“å–æ’­å®¢æ•°æ®
        run: |
          python << 'EOF'
          import requests
          import json
          import os
          from datetime import datetime
          
          # å®šä¹‰è¦æŠ“å–çš„æ•°æ®æº
          sources = {
              'full': 'https://xyzrank.eddiehe.top/full.json',
              'new_podcasts': 'https://xyzrank.eddiehe.top/new_podcasts.json',
              'hot_episodes': 'https://xyzrank.eddiehe.top/hot_episodes.json',
              'hot_episodes_new': 'https://xyzrank.eddiehe.top/hot_episodes_new.json'
          }
          
          # åˆ›å»ºæ•°æ®ç›®å½•
          os.makedirs('data', exist_ok=True)
          
          # æŠ“å–æ‰€æœ‰æ•°æ®
          results = {}
          for name, url in sources.items():
              try:
                  print(f"\næ­£åœ¨æŠ“å–: {name}...")
                  response = requests.get(url, timeout=30)
                  response.raise_for_status()
                  data = response.json()
                  
                  # ä¿å­˜åˆ°æ–‡ä»¶
                  filename = f'data/{name}.json'
                  with open(filename, 'w', encoding='utf-8') as f:
                      json.dump(data, f, ensure_ascii=False, indent=2)
                  
                  results[name] = data
                  
                  # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
                  if 'data' in data:
                      if 'episodes' in data['data']:
                          count = len(data['data']['episodes'])
                          print(f"âœ“ {name}: æˆåŠŸæŠ“å– {count} ä¸ªæ’­å®¢å•é›†")
                      elif 'podcasts' in data['data']:
                          count = len(data['data']['podcasts'])
                          print(f"âœ“ {name}: æˆåŠŸæŠ“å– {count} ä¸ªæ’­å®¢")
                  else:
                      print(f"âœ“ {name}: æŠ“å–æˆåŠŸ")
                      
              except Exception as e:
                  print(f"âœ— {name}: æŠ“å–å¤±è´¥ - {str(e)}")
          
          print(f"\næŠ“å–å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
          EOF
      
      # æ­¥éª¤5ï¼šç”Ÿæˆç»¼åˆæŠ¥å‘Š
      - name: ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        run: |
          python << 'EOF'
          import json
          import os
          from datetime import datetime
          
          # è¯»å–æ‰€æœ‰æ•°æ®
          data_files = {
              'full': 'data/full.json',
              'new_podcasts': 'data/new_podcasts.json',
              'hot_episodes': 'data/hot_episodes.json',
              'hot_episodes_new': 'data/hot_episodes_new.json'
          }
          
          datasets = {}
          for name, filepath in data_files.items():
              if os.path.exists(filepath):
                  with open(filepath, 'r', encoding='utf-8') as f:
                      datasets[name] = json.load(f)
          
          # ç”Ÿæˆ Markdown æŠ¥å‘Š
          report = f"""# ğŸ™ï¸ ä¸­æ–‡æ’­å®¢çƒ­æ¦œ

> æ•°æ®æ¥æº: [xyzrank.eddiehe.top](https://xyzrank.eddiehe.top)  
> æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
> è‡ªåŠ¨æ›´æ–°: æ¯6å°æ—¶

---

## ğŸ“Š æ•°æ®ç»Ÿè®¡

"""
          
          # ç»Ÿè®¡ä¿¡æ¯
          if 'hot_episodes' in datasets and 'data' in datasets['hot_episodes']:
              hot_count = len(datasets['hot_episodes']['data'].get('episodes', []))
              report += f"- ğŸ”¥ çƒ­é—¨å•é›†: {hot_count} ä¸ª\n"
          
          if 'hot_episodes_new' in datasets and 'data' in datasets['hot_episodes_new']:
              new_hot_count = len(datasets['hot_episodes_new']['data'].get('episodes', []))
              report += f"- ğŸ†• æ–°çƒ­é—¨å•é›†: {new_hot_count} ä¸ª\n"
          
          if 'new_podcasts' in datasets and 'data' in datasets['new_podcasts']:
              new_podcast_count = len(datasets['new_podcasts']['data'].get('podcasts', []))
              report += f"- âœ¨ æ–°æ’­å®¢: {new_podcast_count} ä¸ª\n"
          
          if 'full' in datasets and 'data' in datasets['full']:
              full_count = len(datasets['full']['data'].get('podcasts', []))
              report += f"- ğŸ“š å…¨éƒ¨æ’­å®¢: {full_count} ä¸ª\n"
          
          report += "\n---\n\n"
          
          # çƒ­é—¨å•é›† Top 10
          if 'hot_episodes' in datasets and 'data' in datasets['hot_episodes']:
              episodes = datasets['hot_episodes']['data'].get('episodes', [])
              report += "## ğŸ”¥ çƒ­é—¨å•é›† Top 10\n\n"
              
              for i, ep in enumerate(episodes[:10], 1):
                  report += f"""### {i}. {ep.get('title', 'æœªçŸ¥æ ‡é¢˜')}

- **æ’­å®¢**: {ep.get('podcastName', 'æœªçŸ¥')}
- **æ’­æ”¾é‡**: {ep.get('playCount', 0):,}
- **è¯„è®ºæ•°**: {ep.get('commentCount', 0):,}
- **æ—¶é•¿**: {ep.get('duration', 0)} åˆ†é’Ÿ
- **å‘å¸ƒæ—¶é—´**: {ep.get('postTime', 'æœªçŸ¥')[:10]}
- **é“¾æ¥**: [æ”¶å¬]({ep.get('link', '#')})

"""
          
          # æ–°çƒ­é—¨å•é›† Top 5
          if 'hot_episodes_new' in datasets and 'data' in datasets['hot_episodes_new']:
              episodes_new = datasets['hot_episodes_new']['data'].get('episodes', [])
              report += "\n---\n\n## ğŸ†• æ–°çƒ­é—¨å•é›† Top 5\n\n"
              
              for i, ep in enumerate(episodes_new[:5], 1):
                  report += f"""### {i}. {ep.get('title', 'æœªçŸ¥æ ‡é¢˜')}

- **æ’­å®¢**: {ep.get('podcastName', 'æœªçŸ¥')}
- **æ’­æ”¾é‡**: {ep.get('playCount', 0):,}
- **è¯„è®ºæ•°**: {ep.get('commentCount', 0):,}
- **æ—¶é•¿**: {ep.get('duration', 0)} åˆ†é’Ÿ
- **é“¾æ¥**: [æ”¶å¬]({ep.get('link', '#')})

"""
          
          # æ–°æ’­å®¢ Top 5
          if 'new_podcasts' in datasets and 'data' in datasets['new_podcasts']:
              podcasts = datasets['new_podcasts']['data'].get('podcasts', [])
              report += "\n---\n\n## âœ¨ æ–°æ’­å®¢æ¨è Top 5\n\n"
              
              for i, pod in enumerate(podcasts[:5], 1):
                  report += f"""### {i}. {pod.get('title', 'æœªçŸ¥æ ‡é¢˜')}

- **ä½œè€…**: {pod.get('author', 'æœªçŸ¥')}
- **è®¢é˜…æ•°**: {pod.get('subscription', 0):,}
- **å•é›†æ•°**: {pod.get('totalEpisodesCount', 0)}
- **åˆ†ç±»**: {pod.get('primaryGenreName', 'æœªçŸ¥')}
- **é“¾æ¥**: [è®¢é˜…]({pod.get('link', '#')})

"""
          
          # é¡µè„š
          report += """
---

## ğŸ“ æ•°æ®æ–‡ä»¶

- [å®Œæ•´æ’­å®¢åˆ—è¡¨](data/full.json)
- [æ–°æ’­å®¢åˆ—è¡¨](data/new_podcasts.json)
- [çƒ­é—¨å•é›†](data/hot_episodes.json)
- [æ–°çƒ­é—¨å•é›†](data/hot_episodes_new.json)

---

*æœ¬é¡¹ç›®ç”± GitHub Actions è‡ªåŠ¨æ›´æ–°*
"""
          
          # ä¿å­˜æŠ¥å‘Š
          with open('README.md', 'w', encoding='utf-8') as f:
              f.write(report)
          
          print("âœ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
          EOF
      
      # æ­¥éª¤6ï¼šæäº¤æ›´æ”¹
      - name: æäº¤æ›´æ”¹åˆ°ä»“åº“
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add data/*.json README.md
          git diff --quiet && git diff --staged --quiet || (git commit -m "ğŸ“Š æ›´æ–°æ’­å®¢çƒ­æ¦œæ•°æ® $(date '+%Y-%m-%d %H:%M:%S')" && git push)
